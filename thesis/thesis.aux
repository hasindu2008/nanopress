\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {chapter}{\tocchapter {Chapter}{}{Student Plagiarism: Compliance Statement}}{ii}{chapter*.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec:plagiarism}{{}{ii}{Student Plagiarism: Compliance Statement}{chapter*.2}{}}
\@writefile{toc}{\contentsline {chapter}{\tocchapter {Chapter}{}{Abstract}}{iii}{chapter*.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{svb}
\@writefile{toc}{\contentsline {chapter}{\tocchapter {Chapter}{}{Acknowledgements}}{iv}{chapter*.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\tocchapter {Chapter}{}{List of Figures}}{vii}{chapter*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\tocchapter {Chapter}{}{List of Tables}}{xii}{chapter*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\tocchapter {Chapter}{1}{Introduction}}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces The MinION is a highly portable nanopore sequencing device manufactured by ONT which weighs only 450g.\relax }}{1}{figure.caption.7}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:minion}{{1.1}{1}{The MinION is a highly portable nanopore sequencing device manufactured by ONT which weighs only 450g.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces A DNA molecule passing through a nanopore in an electrolytic solution.\relax }}{2}{figure.caption.8}\protected@file@percent }
\newlabel{fig:dna-nano}{{1.2}{2}{A DNA molecule passing through a nanopore in an electrolytic solution.\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{1.1}{Contributions}}{3}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\tocsection {}{1.2}{Thesis Outline}}{3}{section.1.2}\protected@file@percent }
\citation{three-decades-nano}
\citation{Wang2021}
\citation{nano-web}
\citation{Wang2021}
\@writefile{toc}{\contentsline {chapter}{\tocchapter {Chapter}{2}{Literature Review}}{4}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:litreview}{{2}{4}{Literature Review}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{2.1}{Nanopore Sequencing}}{4}{section.2.1}\protected@file@percent }
\citation{shannon}
\citation{shannon}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces The MinION, the first commercially-available nanopore sequencing device, recording nanopore signal data as a double-stranded DNA (dsDNA) molecule is unwound and ratcheted through the nanopore.}}{5}{figure.caption.9}\protected@file@percent }
\newlabel{fig:nano}{{2.1}{5}{The MinION, the first commercially-available nanopore sequencing device, recording nanopore signal data as a double-stranded DNA (dsDNA) molecule is unwound and ratcheted through the nanopore}{figure.caption.9}{}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{2.2}{Data Compression}}{5}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{2.2.1}{Introduction}}{5}{subsection.2.2.1}\protected@file@percent }
\citation{shannon}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Shannon's general communication system consists of an \textit  {information source} which produces a message, a \textit  {transmitter} which manipulates the message to produce a signal suitable for transmission over the channel, a \textit  {channel} which serves as the medium for signal transmission from the transmitter to the receiver, a \textit  {receiver} which reconstructs the message from the signal and a \textit  {destination} which is the message's intended point of delivery.}}{6}{figure.caption.10}\protected@file@percent }
\newlabel{fig:shannon-comm-system}{{2.2}{6}{Shannon's general communication system consists of an \textit {information source} which produces a message, a \textit {transmitter} which manipulates the message to produce a signal suitable for transmission over the channel, a \textit {channel} which serves as the medium for signal transmission from the transmitter to the receiver, a \textit {receiver} which reconstructs the message from the signal and a \textit {destination} which is the message's intended point of delivery}{figure.caption.10}{}}
\citation{info-book}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{2.2.2}{Entropy Coding}}{7}{subsection.2.2.2}\protected@file@percent }
\citation{huffman}
\citation{mcmillan}
\citation{huffman-time}
\citation{fgk,vitter}
\citation{arithmetic-coding}
\citation{arithmetic-coding}
\citation{range-coding}
\citation{byte-pair}
\citation{lzw}
\citation{lz77}
\citation{lz78}
\citation{rle}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{2.2.3}{Dictionary Coding}}{9}{subsection.2.2.3}\protected@file@percent }
\citation{bwt}
\citation{bwt-genomic}
\citation{lemire-simd}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{2.2.4}{Other Encodings}}{10}{subsection.2.2.4}\protected@file@percent }
\newlabel{sec:data-other}{{2.2.4}{10}{Other Encodings}{subsection.2.2.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\tocsubsubsection {}{2.2.4.1}{Integer compression schemes}}{10}{subsubsection.2.2.4.1}\protected@file@percent }
\newlabel{sec:integer-comp}{{2.2.4.1}{10}{Integer compression schemes}{subsubsection.2.2.4.1}{}}
\newlabel{sec:bitpack}{{2.2.4.1}{10}{Integer compression schemes}{subsubsection.2.2.4.1}{}}
\citation{lemire-simd}
\citation{svb}
\citation{svb}
\citation{pod5}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces The sequence of numbers $1024,12,10,\num {524288}$ in the bit packed format. The data is read from left to right, top to bottom with the most significant bits first.}}{11}{figure.caption.11}\protected@file@percent }
\newlabel{fig:bitpack}{{2.3}{11}{The sequence of numbers $1024,12,10,\num {524288}$ in the bit packed format. The data is read from left to right, top to bottom with the most significant bits first}{figure.caption.11}{}}
\newlabel{subsubsec:svb}{{2.2.4.1}{11}{Integer compression schemes}{figure.caption.11}{}}
\citation{vbz}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces The number of bytes used and their control code for different supported integer ranges in classical 32-bit, 0-based and 16-bit Stream VByte.\relax }}{12}{table.caption.12}\protected@file@percent }
\newlabel{tab:groupsvb}{{2.1}{12}{The number of bytes used and their control code for different supported integer ranges in classical 32-bit, 0-based and 16-bit Stream VByte.\relax }{table.caption.12}{}}
\newlabel{fig:svb}{{2.4a}{12}{Subfigure 2 2.4a}{subfigure.2.4.1}{}}
\newlabel{sub@fig:svb}{{(a)}{a}{Subfigure 2 2.4a\relax }{subfigure.2.4.1}{}}
\newlabel{fig:svb-0based}{{2.4b}{12}{Subfigure 2 2.4b}{subfigure.2.4.2}{}}
\newlabel{sub@fig:svb-0based}{{(b)}{b}{Subfigure 2 2.4b\relax }{subfigure.2.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces  An example of $1024,12,10,\num {1048576}, 0,1,2,1024$ compressed with classical and 0-based Stream VByte.}}{12}{figure.caption.13}\protected@file@percent }
\newlabel{fig:groupsvb}{{2.4}{12}{An example of $1024,12,10,\num {1048576}, 0,1,2,1024$ compressed with classical and 0-based Stream VByte}{figure.caption.13}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Compressed classical Stream VByte bytes}}}{12}{subfigure.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Compressed 0-based Stream VByte bytes}}}{12}{subfigure.4.2}\protected@file@percent }
\citation{zstd}
\citation{lemire-simd}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Compressed 16-bit Stream VByte bytes for $1024,12,10,4096, 0,1,2,1024$.}}{13}{figure.caption.14}\protected@file@percent }
\newlabel{fig:svb-16}{{2.5}{13}{Compressed 16-bit Stream VByte bytes for $1024,12,10,4096, 0,1,2,1024$}{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{\tocsubsubsection {}{2.2.4.2}{State-of-the-Art}}{13}{subsubsection.2.2.4.2}\protected@file@percent }
\newlabel{sec:state-of-the-art}{{2.2.4.2}{13}{State-of-the-Art}{subsubsection.2.2.4.2}{}}
\citation{google-zigzag}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{2.2.5}{Signal Compression}}{14}{subsection.2.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\tocsubsubsection {}{2.2.5.1}{Wavelet Compression}}{14}{subsubsection.2.2.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{2.2.6}{Software Codecs}}{14}{subsection.2.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\tocsubsubsection {}{2.2.6.1}{gzip}}{14}{subsubsection.2.2.6.1}\protected@file@percent }
\citation{genomic-comp}
\citation{picopore}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces The zig-zag encoding applied to integers -15 to 15. As we can see, it is similar to the absolute value function but is doubled and shifted on the negative $x$-axis to ensure injectivity.\relax }}{15}{figure.caption.15}\protected@file@percent }
\newlabel{fig:zigzag}{{2.6}{15}{The zig-zag encoding applied to integers -15 to 15. As we can see, it is similar to the absolute value function but is doubled and shifted on the negative $x$-axis to ensure injectivity.\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{\tocsubsubsection {}{2.2.6.2}{Zstandard}}{15}{subsubsection.2.2.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{2.2.7}{Nanopore Compression}}{15}{subsection.2.2.7}\protected@file@percent }
\citation{lossy-nano,lfzip}
\citation{lossy-nano}
\citation{mcdrc}
\citation{shannon}
\citation{huffman}
\citation{rle}
\citation{arithmetic-coding}
\citation{lz77}
\citation{lz78}
\citation{range-coding}
\citation{lzw}
\citation{vitter}
\citation{bwt}
\citation{byte-pair}
\citation{picopore}
\citation{svb}
\citation{lossy-nano}
\citation{mcdrc}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces A timeline of the major events in the literature.\relax }}{17}{table.caption.16}\protected@file@percent }
\newlabel{tab:lit}{{2.2}{17}{A timeline of the major events in the literature.\relax }{table.caption.16}{}}
\@writefile{toc}{\contentsline {chapter}{\tocchapter {Chapter}{3}{The Data}}{18}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:data}{{3}{18}{The Data}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{3.1}{Introduction}}{18}{section.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces The read with ID e9f08690-171f-476f-9119-5330d0290126 from the NA12878 data set plotted against two axes. The primary $y$-axis (left) is the raw signal values and the secondary $y$-axis (right) is the ionic current found using equation \ref  {eq:pa}. $535, 531, 529, 519, 535,\dots  $ is the sequence starting from position 25000 and $106.73, 105.27, 104.54, 100.88, 106.73,\dots  $ is the same sequence after converting to picoamperes (rounded to 2 decimal places).\relax }}{18}{figure.caption.17}\protected@file@percent }
\newlabel{fig:read-e9f-pa}{{3.1}{18}{The read with ID e9f08690-171f-476f-9119-5330d0290126 from the NA12878 data set plotted against two axes. The primary $y$-axis (left) is the raw signal values and the secondary $y$-axis (right) is the ionic current found using equation \ref {eq:pa}. $535, 531, 529, 519, 535,\dots $ is the sequence starting from position 25000 and $106.73, 105.27, 104.54, 100.88, 106.73,\dots $ is the same sequence after converting to picoamperes (rounded to 2 decimal places).\relax }{figure.caption.17}{}}
\citation{slow5-spec}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Some constant metadata of the NA12878 data set.\relax }}{19}{table.caption.18}\protected@file@percent }
\newlabel{tab:data-meta}{{3.1}{19}{Some constant metadata of the NA12878 data set.\relax }{table.caption.18}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces The variable metadata of the read with ID e9f08690-171f-476f-9119-5330d0290126 from the NA12878 data set.\relax }}{19}{table.caption.19}\protected@file@percent }
\newlabel{tab:data-read-meta}{{3.2}{19}{The variable metadata of the read with ID e9f08690-171f-476f-9119-5330d0290126 from the NA12878 data set.\relax }{table.caption.19}{}}
\newlabel{eq:pa}{{3.1}{20}{Introduction}{equation.3.1.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces The original NA12878 data set.\relax }}{21}{table.caption.20}\protected@file@percent }
\newlabel{tab:data-orig}{{3.3}{21}{The original NA12878 data set.\relax }{table.caption.20}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.4}{\ignorespaces The downsampled NA12878 data set.\relax }}{21}{table.caption.21}\protected@file@percent }
\newlabel{tab:data}{{3.4}{21}{The downsampled NA12878 data set.\relax }{table.caption.21}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.5}{\ignorespaces  Summary statistics of the data's raw signal values.\relax }}{22}{table.caption.22}\protected@file@percent }
\newlabel{tab:rawsig}{{3.5}{22}{Summary statistics of the data's raw signal values.\relax }{table.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces The frequency of raw signal values 295 to 687 in millions for the data set. The raw signal values outside this range occurred less than 1 million times (or with a probability lesser than 0.002\%).\relax }}{22}{figure.caption.23}\protected@file@percent }
\newlabel{fig:data-hist}{{3.2}{22}{The frequency of raw signal values 295 to 687 in millions for the data set. The raw signal values outside this range occurred less than 1 million times (or with a probability lesser than 0.002\%).\relax }{figure.caption.23}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.6}{\ignorespaces  Summary statistics of the data's read lengths.\relax }}{23}{table.caption.24}\protected@file@percent }
\newlabel{tab:n}{{3.6}{23}{Summary statistics of the data's read lengths.\relax }{table.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Histogram of the number of data points in (length of) each read for the data set. The distribution appears to modelled by an exponential or Gamma distribution.\relax }}{23}{figure.caption.25}\protected@file@percent }
\newlabel{fig:n-hist}{{3.3}{23}{Histogram of the number of data points in (length of) each read for the data set. The distribution appears to modelled by an exponential or Gamma distribution.\relax }{figure.caption.25}{}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{3.2}{Characteristics}}{24}{section.3.2}\protected@file@percent }
\newlabel{sec:data:char}{{3.2}{24}{Characteristics}{section.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces The first 1500 data points of the read with ID e9f08690-171f-476f-9119-5330d0290126 split into four sections: surge (before the red line), stall (between red and orange), pre-adapter surge (between orange and blue) and adapter sequence (after blue). In order from left to right the vertical lines are coloured red, orange and blue.\relax }}{25}{figure.caption.26}\protected@file@percent }
\newlabel{fig:start-sections}{{3.4}{25}{The first 1500 data points of the read with ID e9f08690-171f-476f-9119-5330d0290126 split into four sections: surge (before the red line), stall (between red and orange), pre-adapter surge (between orange and blue) and adapter sequence (after blue). In order from left to right the vertical lines are coloured red, orange and blue.\relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces An example of 200 data points from a DNA section in the read with ID e9f08690-171f-476f-9119-5330d0290126. It is characterised by smaller low-variance sections with steep transitions between them.\relax }}{26}{figure.caption.27}\protected@file@percent }
\newlabel{fig:dna-section}{{3.5}{26}{An example of 200 data points from a DNA section in the read with ID e9f08690-171f-476f-9119-5330d0290126. It is characterised by smaller low-variance sections with steep transitions between them.\relax }{figure.caption.27}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.7}{\ignorespaces  Summary statistics of the data's raw signal values (None) and its various transformations.\relax }}{26}{table.caption.32}\protected@file@percent }
\newlabel{tab:trans}{{3.7}{26}{Summary statistics of the data's raw signal values (None) and its various transformations.\relax }{table.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces An example of a homopolymer section (repetition of `T') from the read with ID e9f08690-171f-476f-9119-5330d0290126. The thymine DNA base is repeated 33 times in the homopolymer.\relax }}{27}{figure.caption.28}\protected@file@percent }
\newlabel{fig:homo-section}{{3.6}{27}{An example of a homopolymer section (repetition of `T') from the read with ID e9f08690-171f-476f-9119-5330d0290126. The thymine DNA base is repeated 33 times in the homopolymer.\relax }{figure.caption.28}{}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{3.3}{Transformations}}{27}{section.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces An example of 3800 data points from a slow section in the read with ID 99671b17-feb4-492b-b119-77daf8e5794e. It is characterised by extended low-variance sections between regular DNA sections. The 6-mers GTCCCA, TCCCAA and CCAAGT are mapped to the regions between the red and orange, orange and blue, and blue and purple vertical lines respectively. CCCAAG is also mapped to the orange-blue region but not as cleanly. In order from left to right the vertical lines are coloured red, orange, blue and purple.\relax }}{28}{figure.caption.29}\protected@file@percent }
\newlabel{fig:slow-section}{{3.7}{28}{An example of 3800 data points from a slow section in the read with ID 99671b17-feb4-492b-b119-77daf8e5794e. It is characterised by extended low-variance sections between regular DNA sections. The 6-mers GTCCCA, TCCCAA and CCAAGT are mapped to the regions between the red and orange, orange and blue, and blue and purple vertical lines respectively. CCCAAG is also mapped to the orange-blue region but not as cleanly. In order from left to right the vertical lines are coloured red, orange, blue and purple.\relax }{figure.caption.29}{}}
\newlabel{subsec:prob}{{3.3}{28}{Transformations}{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces An example of an incongruent section from the same read used in Figures \ref  {fig:start-sections}, \ref  {fig:dna-section} and \ref  {fig:homo-section}. The incongruent section's median signal level is $\sim $ 620 compared to the whole's read's median which is $\sim $ 550.\relax }}{29}{figure.caption.30}\protected@file@percent }
\newlabel{fig:mess-section}{{3.8}{29}{An example of an incongruent section from the same read used in Figures \ref {fig:start-sections}, \ref {fig:dna-section} and \ref {fig:homo-section}. The incongruent section's median signal level is $\sim $ 620 compared to the whole's read's median which is $\sim $ 550.\relax }{figure.caption.30}{}}
\newlabel{subsec:stripe}{{3.3}{29}{Transformations}{figure.caption.35}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces The read with ID 515e4fd0-8ab1-4845-8866-6772e779712b from the data set. There is an unpredictable fall at the end of the read possibly related to its shorter length of 7329.\relax }}{30}{figure.caption.31}\protected@file@percent }
\newlabel{fig:read-515}{{3.9}{30}{The read with ID 515e4fd0-8ab1-4845-8866-6772e779712b from the data set. There is an unpredictable fall at the end of the read possibly related to its shorter length of 7329.\relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces The deltas of the read with ID e9f08690-171f-476f-9119-5330d0290126. $-4, -2, -10, 16,\dots  $ is the sequence starting from position 25000.\relax }}{30}{figure.caption.33}\protected@file@percent }
\newlabel{fig:read-e9f-delta}{{3.10}{30}{The deltas of the read with ID e9f08690-171f-476f-9119-5330d0290126. $-4, -2, -10, 16,\dots $ is the sequence starting from position 25000.\relax }{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces The frequency of raw signal deltas -80 to 112 in millions for the data set. The deltas outside this range occurred less than 1 million times.\relax }}{31}{figure.caption.34}\protected@file@percent }
\newlabel{fig:delta-hist}{{3.11}{31}{The frequency of raw signal deltas -80 to 112 in millions for the data set. The deltas outside this range occurred less than 1 million times.\relax }{figure.caption.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces The zig-zag deltas of the read with ID e9f08690-171f-476f-9119-5330d0290126. $7, 3, 19, 32,\dots  $ is the sequence starting from position 25000.\relax }}{31}{figure.caption.35}\protected@file@percent }
\newlabel{fig:read-e9f-zd}{{3.12}{31}{The zig-zag deltas of the read with ID e9f08690-171f-476f-9119-5330d0290126. $7, 3, 19, 32,\dots $ is the sequence starting from position 25000.\relax }{figure.caption.35}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces The frequency of raw signal zig-zag deltas 0 to 224 in millions for the data set. The zig-zag deltas outside this range occurred less than 1 million times.\relax }}{32}{figure.caption.36}\protected@file@percent }
\newlabel{fig:zd-hist}{{3.13}{32}{The frequency of raw signal zig-zag deltas 0 to 224 in millions for the data set. The zig-zag deltas outside this range occurred less than 1 million times.\relax }{figure.caption.36}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.8}{\ignorespaces  The entropy of the data and its transformations.\relax }}{32}{table.caption.37}\protected@file@percent }
\newlabel{tab:entropy}{{3.8}{32}{The entropy of the data and its transformations.\relax }{table.caption.37}{}}
\@writefile{toc}{\contentsline {chapter}{\tocchapter {Chapter}{4}{Problem Space}}{33}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:probspace}{{4}{33}{Problem Space}{chapter.4}{}}
\@writefile{toc}{\contentsline {chapter}{\tocchapter {Chapter}{5}{Methodology}}{37}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:methodology}{{5}{37}{Methodology}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{5.1}{One Byte, Two Byte Exceptions}}{37}{section.5.1}\protected@file@percent }
\newlabel{sec:vbbe21}{{5.1}{37}{One Byte, Two Byte Exceptions}{section.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces  The vbe21 encoding takes two byte integers $x_1,x_2,\dots  ,x_n$ and encodes those which cannot fit into one byte as \textit  {exceptions} at the beginning of the stream. There are $e$ exceptions which are recorded by their original positions $p_1,p_2,\dots  ,p_e$ and values $x_{p_1},x_{p_2},\dots  ,x_{p_e}$. Following this is the regular one byte data where $q_i$ is the original position of the $i$-th one byte data point. This is beneficial when there are few exceptions in the data.\relax }}{37}{figure.caption.38}\protected@file@percent }
\newlabel{fig:vbe21}{{5.1}{37}{The vbe21 encoding takes two byte integers $x_1,x_2,\dots ,x_n$ and encodes those which cannot fit into one byte as \textit {exceptions} at the beginning of the stream. There are $e$ exceptions which are recorded by their original positions $p_1,p_2,\dots ,p_e$ and values $x_{p_1},x_{p_2},\dots ,x_{p_e}$. Following this is the regular one byte data where $q_i$ is the original position of the $i$-th one byte data point. This is beneficial when there are few exceptions in the data.\relax }{figure.caption.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces  An example of $1024,12,10,4096, 0,1,2,1024$ encoded with vbe21. The encoding order is read from left to right and top to bottom. There are 3 exceptions located at positions 0, 3 and 7 with values 1024, 4096 and 1024. It uses 25 bytes in total.\relax }}{38}{figure.caption.39}\protected@file@percent }
\newlabel{fig:vbe21-eg}{{5.2}{38}{An example of $1024,12,10,4096, 0,1,2,1024$ encoded with vbe21. The encoding order is read from left to right and top to bottom. There are 3 exceptions located at positions 0, 3 and 7 with values 1024, 4096 and 1024. It uses 25 bytes in total.\relax }{figure.caption.39}{}}
\newlabel{eq:vbe21}{{{$*$}}{38}{One Byte, Two Byte Exceptions}{AMS.41}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{5.1.1}{Exceptions Encoding}}{39}{subsection.5.1.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces  Summary statistics of the number of exceptions per read and the zig-zag delta exceptions themselves in the data.\relax }}{40}{table.caption.42}\protected@file@percent }
\newlabel{tab:ex}{{5.1}{40}{Summary statistics of the number of exceptions per read and the zig-zag delta exceptions themselves in the data.\relax }{table.caption.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Histogram of the number of exceptions per read up to 100 which appears to nicely follow an exponential distribution. Values after 100 occur highly infrequently -- there are only 546 out of \num {500000} reads with more than 100 exceptions.\relax }}{41}{figure.caption.43}\protected@file@percent }
\newlabel{fig:nex-hist}{{5.3}{41}{Histogram of the number of exceptions per read up to 100 which appears to nicely follow an exponential distribution. Values after 100 occur highly infrequently -- there are only 546 out of \num {500000} reads with more than 100 exceptions.\relax }{figure.caption.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Histogram of the zig-zag delta exceptions up to 500. This figure is the tail of Figure \ref  {fig:zd-hist}. The right and left tail of Figure \ref  {fig:delta-hist} are `meshed' together during the zig-zag transformation causing the stripped pattern.\relax }}{42}{figure.caption.44}\protected@file@percent }
\newlabel{fig:ex-hist}{{5.4}{42}{Histogram of the zig-zag delta exceptions up to 500. This figure is the tail of Figure \ref {fig:zd-hist}. The right and left tail of Figure \ref {fig:delta-hist} are `meshed' together during the zig-zag transformation causing the stripped pattern.\relax }{figure.caption.44}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces The compact vbbe21 takes $n$ unsigned 16-bit integers and finds those which cannot fit into one byte. These are encoded by bit packing the number of exceptions, the deltas of the exceptions' positions and the two byte exceptions subtracted by 256. Less than one byte is used for padding to align the bit packed data to the next byte boundary. Then, the one byte data is recorded as in vbe21.\relax }}{43}{figure.caption.45}\protected@file@percent }
\newlabel{fig:vbbe21-compact}{{5.5}{43}{The compact vbbe21 takes $n$ unsigned 16-bit integers and finds those which cannot fit into one byte. These are encoded by bit packing the number of exceptions, the deltas of the exceptions' positions and the two byte exceptions subtracted by 256. Less than one byte is used for padding to align the bit packed data to the next byte boundary. Then, the one byte data is recorded as in vbe21.\relax }{figure.caption.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces The vbbe21 encoding takes $n$ unsigned 16-bit integers and finds those which cannot fit into one byte. These are encoded by storing the number of exceptions using two bytes, bit packing the deltas of the exceptions' positions and bit packing the exceptions themselves. Bit packing is performed using one byte for the number of bits and padding is used between the exception's positions, data and the one byte data. This is easier to implement than compact vbbe21.\relax }}{43}{figure.caption.46}\protected@file@percent }
\newlabel{fig:vbbe21}{{5.6}{43}{The vbbe21 encoding takes $n$ unsigned 16-bit integers and finds those which cannot fit into one byte. These are encoded by storing the number of exceptions using two bytes, bit packing the deltas of the exceptions' positions and bit packing the exceptions themselves. Bit packing is performed using one byte for the number of bits and padding is used between the exception's positions, data and the one byte data. This is easier to implement than compact vbbe21.\relax }{figure.caption.46}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces  The estimated expected size of the exceptions section for encodings vbe21-zd, vbbe21-zd and compact vbbe21-zd on the data.\relax }}{44}{table.caption.47}\protected@file@percent }
\newlabel{tab:ex-sec-exp}{{5.2}{44}{The estimated expected size of the exceptions section for encodings vbe21-zd, vbbe21-zd and compact vbbe21-zd on the data.\relax }{table.caption.47}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces  The naive encoding of the Huffman table where $c_i$ is the Huffman code of symbol $s_i$ with bit length $b_i$; $i$ ranges from 1 to $m$ (the number of table entries).\relax }}{45}{figure.caption.48}\protected@file@percent }
\newlabel{fig:huff-tab}{{5.7}{45}{The naive encoding of the Huffman table where $c_i$ is the Huffman code of symbol $s_i$ with bit length $b_i$; $i$ ranges from 1 to $m$ (the number of table entries).\relax }{figure.caption.48}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{5.1.2}{Huffman}}{45}{subsection.5.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces The Huffman code length of each one-byte zig-zag delta from the shared Huffman table, generated using the frequency distribution of the whole data set.\relax }}{47}{figure.caption.49}\protected@file@percent }
\newlabel{fig:shuff-len}{{5.8}{47}{The Huffman code length of each one-byte zig-zag delta from the shared Huffman table, generated using the frequency distribution of the whole data set.\relax }{figure.caption.49}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{5.1.3}{Range Coding}}{47}{subsection.5.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\tocsection {}{5.2}{Exploiting the Signal}}{49}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{5.2.1}{Subsequence Searching}}{49}{subsection.5.2.1}\protected@file@percent }
\newlabel{alg:rec}{{1}{51}{Find the minimum compressed size $|C_M(x,\hat s)|$ recursively.\relax }{algorithm.1}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Find the minimum compressed size $|C_M(x,\hat  s)|$ recursively.\relax }}{51}{algorithm.1}\protected@file@percent }
\newlabel{alg:dyn}{{2}{52}{Find the minimum compressed size $|C_M(x,\hat s)|$ using dynamic programming.\relax }{algorithm.2}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Find the minimum compressed size $|C_M(x,\hat  s)|$ using dynamic programming.\relax }}{52}{algorithm.2}\protected@file@percent }
\newlabel{alg:dyn-approx}{{3}{54}{Approximate the minimum compressed size $|C_M(x,\hat s)|$ using dynamic programming.\relax }{algorithm.3}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Approximate the minimum compressed size $|C_M(x,\hat  s)|$ using dynamic programming.\relax }}{54}{algorithm.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces The stall from the read with ID e9f08690-171f-476f-9119-5330d0290126 spanning data points 20 to 778.\relax }}{55}{figure.caption.50}\protected@file@percent }
\newlabel{fig:stall}{{5.9}{55}{The stall from the read with ID e9f08690-171f-476f-9119-5330d0290126 spanning data points 20 to 778.\relax }{figure.caption.50}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{5.2.2}{The Stall}}{55}{subsection.5.2.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces  Summary statistics of the data's stall lengths.\relax }}{56}{table.caption.51}\protected@file@percent }
\newlabel{tab:stall-n}{{5.3}{56}{Summary statistics of the data's stall lengths.\relax }{table.caption.51}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces The stall encoding records the stall's starting position in the read, length, compressed size and compressed data, followed by the non-stall's compressed size and compressed data. The specific and generic compression algorithms used are known beforehand and hence are not stored. stall-fz uses rc01s-vbbe21-for and rc01s-vbbe21-zd as the specific and generic algorithm respectively.\relax }}{57}{figure.caption.52}\protected@file@percent }
\newlabel{fig:stall-enc}{{5.10}{57}{The stall encoding records the stall's starting position in the read, length, compressed size and compressed data, followed by the non-stall's compressed size and compressed data. The specific and generic compression algorithms used are known beforehand and hence are not stored. stall-fz uses rc01s-vbbe21-for and rc01s-vbbe21-zd as the specific and generic algorithm respectively.\relax }{figure.caption.52}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces The dstall encoding stores an extra byte at the beginning to mark whether the stall is being encoded or not. If it is being encoded the remaining data matches the stall encoding. Otherwise, $r_s$ is empty and the whole read is compressed using the generic algorithm as usual. That is, the read's compressed size (4 bytes) and data follows the flag.\relax }}{57}{figure.caption.53}\protected@file@percent }
\newlabel{fig:dstall-enc}{{5.11}{57}{The dstall encoding stores an extra byte at the beginning to mark whether the stall is being encoded or not. If it is being encoded the remaining data matches the stall encoding. Otherwise, $r_s$ is empty and the whole read is compressed using the generic algorithm as usual. That is, the read's compressed size (4 bytes) and data follows the flag.\relax }{figure.caption.53}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.12}{\ignorespaces A scatter plot of the compression methods with the highest compression ratio on each read out of rc01s-vbbe21-zd and stall-fz. The best compression ratio is plotted against the length of the read's stall. Reads with a stall length $\sim $1500 and greater are more likely to be compressed smaller with stall-fz rather than rc01s-vbbe21-zd.\relax }}{58}{figure.caption.54}\protected@file@percent }
\newlabel{fig:stall-best}{{5.12}{58}{A scatter plot of the compression methods with the highest compression ratio on each read out of rc01s-vbbe21-zd and stall-fz. The best compression ratio is plotted against the length of the read's stall. Reads with a stall length $\sim $1500 and greater are more likely to be compressed smaller with stall-fz rather than rc01s-vbbe21-zd.\relax }{figure.caption.54}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{5.2.3}{The DNA Section}}{58}{subsection.5.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.13}{\ignorespaces An example of 300 data points from a DNA section in the read with ID e9f08690-171f-476f-9119-5330d0290126. Notice the sudden transitions up and down (jumps and falls) between low-variance sections (flats).\relax }}{59}{figure.caption.55}\protected@file@percent }
\newlabel{fig:dna300-section}{{5.13}{59}{An example of 300 data points from a DNA section in the read with ID e9f08690-171f-476f-9119-5330d0290126. Notice the sudden transitions up and down (jumps and falls) between low-variance sections (flats).\relax }{figure.caption.55}{}}
\@writefile{toc}{\contentsline {subsubsection}{\tocsubsubsection {}{5.2.3.1}{Separating the Jumps, Falls and Flats}}{59}{subsubsection.5.2.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.14}{\ignorespaces 300 data points from a DNA section in the read with ID e9f08690-171f-476f-9119-5330d0290126. The strictly increasing and decreasing sequences are coloured by their maximum absolute delta. Those with a maximum absolute delta greater than 20 are labelled by this value.\relax }}{61}{figure.caption.56}\protected@file@percent }
\newlabel{fig:epsilon}{{5.14}{61}{300 data points from a DNA section in the read with ID e9f08690-171f-476f-9119-5330d0290126. The strictly increasing and decreasing sequences are coloured by their maximum absolute delta. Those with a maximum absolute delta greater than 20 are labelled by this value.\relax }{figure.caption.56}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.15}{\ignorespaces 300 data points from a DNA section in the read with ID e9f08690-171f-476f-9119-5330d0290126. The jumps and falls are highlighted for $\epsilon =24$.\relax }}{62}{figure.caption.57}\protected@file@percent }
\newlabel{fig:epsilon-25}{{5.15}{62}{300 data points from a DNA section in the read with ID e9f08690-171f-476f-9119-5330d0290126. The jumps and falls are highlighted for $\epsilon =24$.\relax }{figure.caption.57}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.16}{\ignorespaces The jumps encoding stores the number of jumps and falls, and the first data point in the read since the deltas are being encoded. The starting indices of the jumps and falls are compressed then their lengths are compressed. Next, the deltas of the jumps and the negative deltas of the falls are compressed together, followed by the zig-zag deltas of the flats. There are opportunities for four different compression techniques given the different data streams.\relax }}{63}{figure.caption.58}\protected@file@percent }
\newlabel{fig:jumps-enc}{{5.16}{63}{The jumps encoding stores the number of jumps and falls, and the first data point in the read since the deltas are being encoded. The starting indices of the jumps and falls are compressed then their lengths are compressed. Next, the deltas of the jumps and the negative deltas of the falls are compressed together, followed by the zig-zag deltas of the flats. There are opportunities for four different compression techniques given the different data streams.\relax }{figure.caption.58}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.17}{\ignorespaces The alternative jumps encoding which differentiates jumps from falls by recording their zig-zag deltas rather than absolute deltas. The jumps/falls and flats are differentiated from each other by a flag bit stream where 1 represents a jump/fall and 0 a flat. The lengths of the jumps/falls and flats are interleaved.\relax }}{64}{figure.caption.59}\protected@file@percent }
\newlabel{fig:jumps-enc-alt1}{{5.17}{64}{The alternative jumps encoding which differentiates jumps from falls by recording their zig-zag deltas rather than absolute deltas. The jumps/falls and flats are differentiated from each other by a flag bit stream where 1 represents a jump/fall and 0 a flat. The lengths of the jumps/falls and flats are interleaved.\relax }{figure.caption.59}{}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{5.3}{Wavelet}}{64}{section.5.3}\protected@file@percent }
\citation{c-clock}
\@writefile{toc}{\contentsline {chapter}{\tocchapter {Chapter}{6}{Results}}{65}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:results}{{6}{65}{Results}{chapter.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6.1}{\ignorespaces  Specifications of the server used for the experiments.\relax }}{65}{table.caption.60}\protected@file@percent }
\newlabel{tab:server}{{6.1}{65}{Specifications of the server used for the experiments.\relax }{table.caption.60}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces The compression ratio of each method on the data. The state-of-the-art method is highlighted in a darker grey. The solid and dotted vertical lines represents the compression ratio equivalent of the entropy of the data and its deltas respectively.\relax }}{67}{figure.caption.65}\protected@file@percent }
\newlabel{fig:results-ratio}{{6.1}{67}{The compression ratio of each method on the data. The state-of-the-art method is highlighted in a darker grey. The solid and dotted vertical lines represents the compression ratio equivalent of the entropy of the data and its deltas respectively.\relax }{figure.caption.65}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6.2}{\ignorespaces  The compression ratio, bits used per symbol and compressed size (in GiB) of the data set after compressing each read sequentially using each of the given methods. It is sorted by compression ratio (lowest to highest) and the state-of-the-art method is highlighted in grey. The methods which have a greater compression ratio than the state-of-the-art are highlighted in a lighter grey. The two horizontal lines represent the entropy of the data (7.70 bits per symbol) and the entropy of the deltas (5.39 bits per symbol). Hence, methods below the first horizontal line have fewer bits per symbol than the entropy of the data and so are suitable. A hyphen (`-') between methods means that they are applied to the original data in layers from right to left.\relax }}{68}{table.caption.61}\protected@file@percent }
\newlabel{tab:results-space}{{6.2}{68}{The compression ratio, bits used per symbol and compressed size (in GiB) of the data set after compressing each read sequentially using each of the given methods. It is sorted by compression ratio (lowest to highest) and the state-of-the-art method is highlighted in grey. The methods which have a greater compression ratio than the state-of-the-art are highlighted in a lighter grey. The two horizontal lines represent the entropy of the data (7.70 bits per symbol) and the entropy of the deltas (5.39 bits per symbol). Hence, methods below the first horizontal line have fewer bits per symbol than the entropy of the data and so are suitable. A hyphen (`-') between methods means that they are applied to the original data in layers from right to left.\relax }{table.caption.61}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6.3}{\ignorespaces  The total compression and decompression time in hours per TiB and the compression ratio after compressing each read from the data sequentially using each of the given methods. It is sorted by the compression time (fastest to slowest) and the state-of-the-art method is highlighted in grey. The methods which have a greater compression ratio than the state-of-the-art are highlighted in a lighter grey.\relax }}{69}{table.caption.62}\protected@file@percent }
\newlabel{tab:results-time-com}{{6.3}{69}{The total compression and decompression time in hours per TiB and the compression ratio after compressing each read from the data sequentially using each of the given methods. It is sorted by the compression time (fastest to slowest) and the state-of-the-art method is highlighted in grey. The methods which have a greater compression ratio than the state-of-the-art are highlighted in a lighter grey.\relax }{table.caption.62}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6.4}{\ignorespaces  The total compression and decompression time in hours per TiB and the compression ratio after compressing each read from the data sequentially using each of the given methods. The data is equivalent to Table \ref  {tab:results-time-com} but it is sorted by the decompression time (fastest to slowest). The state-of-the-art method is highlighted in grey and the methods which have a greater compression ratio than the state-of-the-art are highlighted in a lighter grey.\relax }}{70}{table.caption.63}\protected@file@percent }
\newlabel{tab:results-time-dec}{{6.4}{70}{The total compression and decompression time in hours per TiB and the compression ratio after compressing each read from the data sequentially using each of the given methods. The data is equivalent to Table \ref {tab:results-time-com} but it is sorted by the decompression time (fastest to slowest). The state-of-the-art method is highlighted in grey and the methods which have a greater compression ratio than the state-of-the-art are highlighted in a lighter grey.\relax }{table.caption.63}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6.5}{\ignorespaces A two-way table of the space saving after applying a compression method in the first layer followed by one in the second layer. The method with the highest space saving for each second layer is highlighted in grey, and the method with the highest space saving overall is highlighted in a darker grey.\relax }}{71}{table.caption.64}\protected@file@percent }
\newlabel{tab:results-layer}{{6.5}{71}{A two-way table of the space saving after applying a compression method in the first layer followed by one in the second layer. The method with the highest space saving for each second layer is highlighted in grey, and the method with the highest space saving overall is highlighted in a darker grey.\relax }{table.caption.64}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces The space saving of each method on the data. The state-of-the-art method is highlighted in a darker grey. The solid and dotted vertical lines represents the space saving equivalent of the entropy of the data and its deltas respectively.\relax }}{71}{figure.caption.66}\protected@file@percent }
\newlabel{fig:results-ss}{{6.2}{71}{The space saving of each method on the data. The state-of-the-art method is highlighted in a darker grey. The solid and dotted vertical lines represents the space saving equivalent of the entropy of the data and its deltas respectively.\relax }{figure.caption.66}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces The average number of bits used per symbol and total compressed size of each method on the data. The state-of-the-art method is highlighted in a darker grey. The solid and dotted vertical lines represents the bits per symbol equivalent of the entropy of the data and its deltas respectively.\relax }}{72}{figure.caption.67}\protected@file@percent }
\newlabel{fig:results-bps}{{6.3}{72}{The average number of bits used per symbol and total compressed size of each method on the data. The state-of-the-art method is highlighted in a darker grey. The solid and dotted vertical lines represents the bits per symbol equivalent of the entropy of the data and its deltas respectively.\relax }{figure.caption.67}{}}
\newlabel{fig:results-ss-ct-big}{{6.4a}{73}{Subfigure 6 6.4a}{subfigure.6.4.1}{}}
\newlabel{sub@fig:results-ss-ct-big}{{(a)}{a}{Subfigure 6 6.4a\relax }{subfigure.6.4.1}{}}
\newlabel{fig:results-ss-ct-small}{{6.4b}{73}{Subfigure 6 6.4b}{subfigure.6.4.2}{}}
\newlabel{sub@fig:results-ss-ct-small}{{(b)}{b}{Subfigure 6 6.4b\relax }{subfigure.6.4.2}{}}
\newlabel{fig:results-ss-dt-big}{{6.4c}{73}{Subfigure 6 6.4c}{subfigure.6.4.3}{}}
\newlabel{sub@fig:results-ss-dt-big}{{(c)}{c}{Subfigure 6 6.4c\relax }{subfigure.6.4.3}{}}
\newlabel{fig:results-ss-dt-small}{{6.4d}{73}{Subfigure 6 6.4d}{subfigure.6.4.4}{}}
\newlabel{sub@fig:results-ss-dt-small}{{(d)}{d}{Subfigure 6 6.4d\relax }{subfigure.6.4.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces The (de)compression time (in hours per TiB) versus space saving of various methods. The state-of-the-art method is coloured in red and the labelled methods are on the space--(de)compression-time frontier. That is, for each labelled method in Figures \ref  {fig:results-ss-ct-big} and \ref  {fig:results-ss-ct-small} there is no other compression method which produces a greater space saving in less time. Whilst for each labelled method in Figures \ref  {fig:results-ss-dt-big} and \ref  {fig:results-ss-dt-small} there is no other compression method which has a greater space saving and decompresses in less time. Figures \ref  {fig:results-ss-ct-big} and \ref  {fig:results-ss-dt-big} show all the methods. Whilst Figures \ref  {fig:results-ss-ct-small} and \ref  {fig:results-ss-dt-small} show the methods which are on their respective froniter and have a space saving greater than or equal to the state-of-the-art.\relax }}{73}{figure.caption.68}\protected@file@percent }
\newlabel{fig:results-ss-t}{{6.4}{73}{The (de)compression time (in hours per TiB) versus space saving of various methods. The state-of-the-art method is coloured in red and the labelled methods are on the space--(de)compression-time frontier. That is, for each labelled method in Figures \ref {fig:results-ss-ct-big} and \ref {fig:results-ss-ct-small} there is no other compression method which produces a greater space saving in less time. Whilst for each labelled method in Figures \ref {fig:results-ss-dt-big} and \ref {fig:results-ss-dt-small} there is no other compression method which has a greater space saving and decompresses in less time. Figures \ref {fig:results-ss-ct-big} and \ref {fig:results-ss-dt-big} show all the methods. Whilst Figures \ref {fig:results-ss-ct-small} and \ref {fig:results-ss-dt-small} show the methods which are on their respective froniter and have a space saving greater than or equal to the state-of-the-art.\relax }{figure.caption.68}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{73}{subfigure.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{73}{subfigure.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{73}{subfigure.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {}}}{73}{subfigure.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces A scatter plot of the methods which have a space saving greater than or equal to the state-of-the-art. Compression time is plotted against decompression time (in hours per TiB) and each point is coloured by its space saving. The state-of-the-art method zstd-svb-zd is in the bottom-left corner.\relax }}{74}{figure.caption.69}\protected@file@percent }
\newlabel{fig:results-ct-dt}{{6.5}{74}{A scatter plot of the methods which have a space saving greater than or equal to the state-of-the-art. Compression time is plotted against decompression time (in hours per TiB) and each point is coloured by its space saving. The state-of-the-art method zstd-svb-zd is in the bottom-left corner.\relax }{figure.caption.69}{}}
\@writefile{toc}{\contentsline {chapter}{\tocchapter {Chapter}{7}{Discussion}}{75}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:disc}{{7}{75}{Discussion}{chapter.7}{}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{7.1}{Experiments}}{75}{section.7.1}\protected@file@percent }
\newlabel{chap:disc:exp}{{7.1}{75}{Experiments}{section.7.1}{}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{7.2}{Future Work}}{77}{section.7.2}\protected@file@percent }
\newlabel{chap:disc:future}{{7.2}{77}{Future Work}{section.7.2}{}}
\citation{lara}
\@writefile{toc}{\contentsline {chapter}{\tocchapter {Chapter}{8}{Conclusion}}{79}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:conclusion}{{8}{79}{Conclusion}{chapter.8}{}}
\bibstyle{style/mybibstyle}
\@writefile{toc}{\contentsline {chapter}{\tocchapter {Chapter}{}{Appendix}}{80}{chapter*.70}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:appendix}{{8}{80}{Appendix}{chapter*.70}{}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{8.1}{Subsequence Searching}}{80}{section.8.1}\protected@file@percent }
\newlabel{app:cn}{{8.1}{80}{Subsequence Searching}{section.8.1}{}}
\newlabel{app:cn-dyn}{{8.1}{80}{Subsequence Searching}{section.8.1}{}}
\bibdata{references}
\bibcite{bwt}{{1}{1994}{{Burrows and Wheeler}}{{}}}
\bibcite{lossy-nano}{{2}{2020{a}}{{Chandak et~al.}}{{Chandak, Tatwawadi, Sridhar, and Weissman}}}
\bibcite{lfzip}{{3}{2020{b}}{{Chandak et~al.}}{{Chandak, Tatwawadi, Wen, Wang, Aparicio~Ojea, and Weissman}}}
\bibcite{mcdrc}{{4}{2021}{{Chen et~al.}}{{Chen, Wu, and Luo}}}
\bibcite{zstd}{{5}{2018}{{Collet and Kucherawy}}{{}}}
\bibcite{info-book}{{6}{1991}{{Cover and Thomas}}{{}}}
\bibcite{bwt-genomic}{{7}{2012}{{Cox et~al.}}{{Cox, Bauer, Jakobi, and Rosone}}}
\bibcite{three-decades-nano}{{8}{2016}{{Deamer et~al.}}{{Deamer, Akeson, and Branton}}}
\bibcite{byte-pair}{{9}{1994}{{Gage}}{{}}}
\bibcite{slow5-spec}{{10}{2022}{{Gamaarachchi et~al.}}{{Gamaarachchi, Samarakoon, Jenner, Ferguson, Amos, Hammond, Saadat, Smith, Parameswaran, and Deveson}}}
\bibcite{picopore}{{11}{2017}{{Gigante}}{{}}}
\bibcite{google-zigzag}{{12}{2022}{{Google}}{{}}}
\bibcite{genomic-comp}{{13}{2019}{{Hernaez et~al.}}{{Hernaez, Pavlichin, Weissman, and Ochoa}}}
\bibcite{huffman}{{14}{1952}{{Huffman}}{{}}}
\bibcite{c-clock}{{15}{2021}{{Kerrisk}}{{}}}
\@writefile{toc}{\contentsline {chapter}{\tocchapter {Chapter}{}{Bibliography}}{81}{chapter*.72}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{fgk}{{16}{1985}{{Knuth}}{{}}}
\bibcite{huffman-time}{{17}{1976}{{Leeuwen}}{{}}}
\bibcite{lemire-simd}{{18}{2014}{{Lemire et~al.}}{{Lemire, Boytsov, and Kurz}}}
\bibcite{svb}{{19}{2018}{{Lemire et~al.}}{{Lemire, Kurz, and Rupp}}}
\bibcite{lara}{{20}{2021}{{Marks}}{{}}}
\bibcite{range-coding}{{21}{1979}{{Martin}}{{}}}
\bibcite{mcmillan}{{22}{1956}{{McMillan}}{{}}}
\bibcite{pod5}{{23}{2022{a}}{{nanoporetech}}{{}}}
\bibcite{vbz}{{24}{2022{b}}{{nanoporetech}}{{}}}
\bibcite{nano-web}{{25}{2022}{{ONT}}{{}}}
\bibcite{arithmetic-coding}{{26}{1976}{{Rissanen}}{{}}}
\bibcite{rle}{{27}{1967}{{Robinson and Cherry}}{{}}}
\bibcite{shannon}{{28}{1948}{{Shannon}}{{}}}
\bibcite{vitter}{{29}{1987}{{Vitter}}{{}}}
\bibcite{Wang2021}{{30}{2021}{{Wang et~al.}}{{Wang, Zhao, Bollas, Wang, and Au}}}
\bibcite{lzw}{{31}{1984}{{Welch}}{{}}}
\bibcite{lz77}{{32}{1977}{{Ziv and Lempel}}{{}}}
\bibcite{lz78}{{33}{1978}{{Ziv and Lempel}}{{}}}
\newlabel{tocindent-1}{0pt}
\newlabel{tocindent0}{58.08931pt}
\newlabel{tocindent1}{24.63747pt}
\newlabel{tocindent2}{32.84995pt}
\newlabel{tocindent3}{0pt}
