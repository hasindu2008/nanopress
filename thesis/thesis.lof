\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces The MinION is a highly portable nanopore sequencing device manufactured by ONT which weighs only 450g.\relax }}{1}{figure.caption.7}%
\contentsline {figure}{\numberline {1.2}{\ignorespaces A DNA molecule passing through a nanopore in an electrolytic solution.\relax }}{2}{figure.caption.8}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces The MinION, the first commercially-available nanopore sequencing device, recording nanopore signal data as a double-stranded DNA (dsDNA) molecule is unwound and ratcheted through the nanopore.}}{5}{figure.caption.9}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Shannon's general communication system consists of an \textit {information source} which produces a message, a \textit {transmitter} which manipulates the message to produce a signal suitable for transmission over the channel, a \textit {channel} which serves as the medium for signal transmission from the transmitter to the receiver, a \textit {receiver} which reconstructs the message from the signal and a \textit {destination} which is the message's intended point of delivery.}}{6}{figure.caption.10}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces The sequence of numbers $1024,12,10,\num {524288}$ in the bit packed format. The data is read from left to right, top to bottom with the most significant bits first.}}{11}{figure.caption.11}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces An example of $1024,12,10,\num {1048576}, 0,1,2,1024$ compressed with classical and 0-based Stream VByte.}}{12}{figure.caption.13}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Compressed classical Stream VByte bytes}}}{12}{subfigure.4.1}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Compressed 0-based Stream VByte bytes}}}{12}{subfigure.4.2}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces Compressed 16-bit Stream VByte bytes for $1024,12,10,4096, 0,1,2,1024$.}}{13}{figure.caption.14}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces The zig-zag encoding applied to integers -15 to 15. As we can see, it is similar to the absolute value function but is doubled and shifted on the negative $x$-axis to ensure injectivity.\relax }}{15}{figure.caption.15}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces The read with ID e9f08690-171f-476f-9119-5330d0290126 from the NA12878 data set plotted against two axes. The primary $y$-axis (left) is the raw signal values and the secondary $y$-axis (right) is the ionic current found using equation \ref {eq:pa}. $535, 531, 529, 519, 535,\dots $ is the sequence starting from position 25000 and $106.73, 105.27, 104.54, 100.88, 106.73,\dots $ is the same sequence after converting to picoamperes (rounded to 2 decimal places).\relax }}{18}{figure.caption.17}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces The frequency of raw signal values 295 to 687 in millions for the data set. The raw signal values outside this range occurred less than 1 million times (or with a probability lesser than 0.002\%).\relax }}{22}{figure.caption.23}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces Histogram of the number of data points in (length of) each read for the data set. The distribution appears to modelled by an exponential or Gamma distribution.\relax }}{23}{figure.caption.25}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces The first 1500 data points of the read with ID e9f08690-171f-476f-9119-5330d0290126 split into four sections: surge (before the red line), stall (between red and orange), pre-adapter surge (between orange and blue) and adapter sequence (after blue). In order from left to right the vertical lines are coloured red, orange and blue.\relax }}{25}{figure.caption.26}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces An example of 200 data points from a DNA section in the read with ID e9f08690-171f-476f-9119-5330d0290126. It is characterised by smaller low-variance sections with steep transitions between them.\relax }}{26}{figure.caption.27}%
\contentsline {figure}{\numberline {3.6}{\ignorespaces An example of a homopolymer section (repetition of `T') from the read with ID e9f08690-171f-476f-9119-5330d0290126. The thymine DNA base is repeated 33 times in the homopolymer.\relax }}{27}{figure.caption.28}%
\contentsline {figure}{\numberline {3.7}{\ignorespaces An example of 3800 data points from a slow section in the read with ID 99671b17-feb4-492b-b119-77daf8e5794e. It is characterised by extended low-variance sections between regular DNA sections. The 6-mers GTCCCA, TCCCAA and CCAAGT are mapped to the regions between the red and orange, orange and blue, and blue and purple vertical lines respectively. CCCAAG is also mapped to the orange-blue region but not as cleanly. In order from left to right the vertical lines are coloured red, orange, blue and purple.\relax }}{28}{figure.caption.29}%
\contentsline {figure}{\numberline {3.8}{\ignorespaces An example of an incongruent section from the same read used in Figures \ref {fig:start-sections}, \ref {fig:dna-section} and \ref {fig:homo-section}. The incongruent section's median signal level is $\sim $ 620 compared to the whole's read's median which is $\sim $ 550.\relax }}{29}{figure.caption.30}%
\contentsline {figure}{\numberline {3.9}{\ignorespaces The read with ID 515e4fd0-8ab1-4845-8866-6772e779712b from the data set. There is an unpredictable fall at the end of the read possibly related to its shorter length of 7329.\relax }}{30}{figure.caption.31}%
\contentsline {figure}{\numberline {3.10}{\ignorespaces The deltas of the read with ID e9f08690-171f-476f-9119-5330d0290126. $-4, -2, -10, 16,\dots $ is the sequence starting from position 25000.\relax }}{30}{figure.caption.33}%
\contentsline {figure}{\numberline {3.11}{\ignorespaces The frequency of raw signal deltas -80 to 112 in millions for the data set. The deltas outside this range occurred less than 1 million times.\relax }}{31}{figure.caption.34}%
\contentsline {figure}{\numberline {3.12}{\ignorespaces The zig-zag deltas of the read with ID e9f08690-171f-476f-9119-5330d0290126. $7, 3, 19, 32,\dots $ is the sequence starting from position 25000.\relax }}{31}{figure.caption.35}%
\contentsline {figure}{\numberline {3.13}{\ignorespaces The frequency of raw signal zig-zag deltas 0 to 224 in millions for the data set. The zig-zag deltas outside this range occurred less than 1 million times.\relax }}{32}{figure.caption.36}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces The vbe21 encoding takes two byte integers $x_1,x_2,\dots ,x_n$ and encodes those which cannot fit into one byte as \textit {exceptions} at the beginning of the stream. There are $e$ exceptions which are recorded by their original positions $p_1,p_2,\dots ,p_e$ and values $x_{p_1},x_{p_2},\dots ,x_{p_e}$. Following this is the regular one byte data where $q_i$ is the original position of the $i$-th one byte data point. This is beneficial when there are few exceptions in the data.\relax }}{37}{figure.caption.38}%
\contentsline {figure}{\numberline {5.2}{\ignorespaces An example of $1024,12,10,4096, 0,1,2,1024$ encoded with vbe21. The encoding order is read from left to right and top to bottom. There are 3 exceptions located at positions 0, 3 and 7 with values 1024, 4096 and 1024. It uses 25 bytes in total.\relax }}{38}{figure.caption.39}%
\contentsline {figure}{\numberline {5.3}{\ignorespaces Histogram of the number of exceptions per read up to 100 which appears to nicely follow an exponential distribution. Values after 100 occur highly infrequently -- there are only 546 out of \num {500000} reads with more than 100 exceptions.\relax }}{41}{figure.caption.43}%
\contentsline {figure}{\numberline {5.4}{\ignorespaces Histogram of the zig-zag delta exceptions up to 500. This figure is the tail of Figure \ref {fig:zd-hist}. The right and left tail of Figure \ref {fig:delta-hist} are `meshed' together during the zig-zag transformation causing the stripped pattern.\relax }}{42}{figure.caption.44}%
\contentsline {figure}{\numberline {5.5}{\ignorespaces The compact vbbe21 takes $n$ unsigned 16-bit integers and finds those which cannot fit into one byte. These are encoded by bit packing the number of exceptions, the deltas of the exceptions' positions and the two byte exceptions subtracted by 256. Less than one byte is used for padding to align the bit packed data to the next byte boundary. Then, the one byte data is recorded as in vbe21.\relax }}{43}{figure.caption.45}%
\contentsline {figure}{\numberline {5.6}{\ignorespaces The vbbe21 encoding takes $n$ unsigned 16-bit integers and finds those which cannot fit into one byte. These are encoded by storing the number of exceptions using two bytes, bit packing the deltas of the exceptions' positions and bit packing the exceptions themselves. Bit packing is performed using one byte for the number of bits and padding is used between the exception's positions, data and the one byte data. This is easier to implement than compact vbbe21.\relax }}{43}{figure.caption.46}%
\contentsline {figure}{\numberline {5.7}{\ignorespaces The naive encoding of the Huffman table where $c_i$ is the Huffman code of symbol $s_i$ with bit length $b_i$; $i$ ranges from 1 to $m$ (the number of table entries).\relax }}{45}{figure.caption.48}%
\contentsline {figure}{\numberline {5.8}{\ignorespaces The Huffman code length of each one-byte zig-zag delta from the shared Huffman table, generated using the frequency distribution of the whole data set.\relax }}{47}{figure.caption.49}%
\contentsline {figure}{\numberline {5.9}{\ignorespaces The stall from the read with ID e9f08690-171f-476f-9119-5330d0290126 spanning data points 20 to 778.\relax }}{55}{figure.caption.50}%
\contentsline {figure}{\numberline {5.10}{\ignorespaces The stall encoding records the stall's starting position in the read, length, compressed size and compressed data, followed by the non-stall's compressed size and compressed data. The specific and generic compression algorithms used are known beforehand and hence are not stored. stall-fz uses rc01s-vbbe21-for and rc01s-vbbe21-zd as the specific and generic algorithm respectively.\relax }}{57}{figure.caption.52}%
\contentsline {figure}{\numberline {5.11}{\ignorespaces The dstall encoding stores an extra byte at the beginning to mark whether the stall is being encoded or not. If it is being encoded the remaining data matches the stall encoding. Otherwise, $r_s$ is empty and the whole read is compressed using the generic algorithm as usual. That is, the read's compressed size (4 bytes) and data follows the flag.\relax }}{57}{figure.caption.53}%
\contentsline {figure}{\numberline {5.12}{\ignorespaces A scatter plot of the compression methods with the highest compression ratio on each read out of rc01s-vbbe21-zd and stall-fz. The best compression ratio is plotted against the length of the read's stall. Reads with a stall length $\sim $1500 and greater are more likely to be compressed smaller with stall-fz rather than rc01s-vbbe21-zd.\relax }}{58}{figure.caption.54}%
\contentsline {figure}{\numberline {5.13}{\ignorespaces An example of 300 data points from a DNA section in the read with ID e9f08690-171f-476f-9119-5330d0290126. Notice the sudden transitions up and down (jumps and falls) between low-variance sections (flats).\relax }}{59}{figure.caption.55}%
\contentsline {figure}{\numberline {5.14}{\ignorespaces 300 data points from a DNA section in the read with ID e9f08690-171f-476f-9119-5330d0290126. The strictly increasing and decreasing sequences are coloured by their maximum absolute delta. Those with a maximum absolute delta greater than 20 are labelled by this value.\relax }}{61}{figure.caption.56}%
\contentsline {figure}{\numberline {5.15}{\ignorespaces 300 data points from a DNA section in the read with ID e9f08690-171f-476f-9119-5330d0290126. The jumps and falls are highlighted for $\epsilon =24$.\relax }}{62}{figure.caption.57}%
\contentsline {figure}{\numberline {5.16}{\ignorespaces The jumps encoding stores the number of jumps and falls, and the first data point in the read since the deltas are being encoded. The starting indices of the jumps and falls are compressed then their lengths are compressed. Next, the deltas of the jumps and the negative deltas of the falls are compressed together, followed by the zig-zag deltas of the flats. There are opportunities for four different compression techniques given the different data streams.\relax }}{63}{figure.caption.58}%
\contentsline {figure}{\numberline {5.17}{\ignorespaces The alternative jumps encoding which differentiates jumps from falls by recording their zig-zag deltas rather than absolute deltas. The jumps/falls and flats are differentiated from each other by a flag bit stream where 1 represents a jump/fall and 0 a flat. The lengths of the jumps/falls and flats are interleaved.\relax }}{64}{figure.caption.59}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {6.1}{\ignorespaces The compression ratio of each method on the data. The state-of-the-art method is highlighted in a darker grey. The solid and dotted vertical lines represents the compression ratio equivalent of the entropy of the data and its deltas respectively.\relax }}{67}{figure.caption.65}%
\contentsline {figure}{\numberline {6.2}{\ignorespaces The space saving of each method on the data. The state-of-the-art method is highlighted in a darker grey. The solid and dotted vertical lines represents the space saving equivalent of the entropy of the data and its deltas respectively.\relax }}{71}{figure.caption.66}%
\contentsline {figure}{\numberline {6.3}{\ignorespaces The average number of bits used per symbol and total compressed size of each method on the data. The state-of-the-art method is highlighted in a darker grey. The solid and dotted vertical lines represents the bits per symbol equivalent of the entropy of the data and its deltas respectively.\relax }}{72}{figure.caption.67}%
\contentsline {figure}{\numberline {6.4}{\ignorespaces The (de)compression time (in hours per TiB) versus space saving of various methods. The state-of-the-art method is coloured in red and the labelled methods are on the space--(de)compression-time frontier. That is, for each labelled method in Figures \ref {fig:results-ss-ct-big} and \ref {fig:results-ss-ct-small} there is no other compression method which produces a greater space saving in less time. Whilst for each labelled method in Figures \ref {fig:results-ss-dt-big} and \ref {fig:results-ss-dt-small} there is no other compression method which has a greater space saving and decompresses in less time. Figures \ref {fig:results-ss-ct-big} and \ref {fig:results-ss-dt-big} show all the methods. Whilst Figures \ref {fig:results-ss-ct-small} and \ref {fig:results-ss-dt-small} show the methods which are on their respective froniter and have a space saving greater than or equal to the state-of-the-art.\relax }}{73}{figure.caption.68}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{73}{subfigure.4.1}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{73}{subfigure.4.2}%
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{73}{subfigure.4.3}%
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{73}{subfigure.4.4}%
\contentsline {figure}{\numberline {6.5}{\ignorespaces A scatter plot of the methods which have a space saving greater than or equal to the state-of-the-art. Compression time is plotted against decompression time (in hours per TiB) and each point is coloured by its space saving. The state-of-the-art method zstd-svb-zd is in the bottom-left corner.\relax }}{74}{figure.caption.69}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
