\section{Exploiting the Signal}

As discussed in Section
\ref{sec:data:char},
there are several predictable characteristics among reads which can be exploited
to gain more compression.

\subsection{The Stall}

To begin with, recall that the stall is the section of a read which occurs at
the beginning between the surge and pre-adapter surge. See Figures
\ref{fig:start-sections} and \ref{fig:stall}. It is thought to occur due to the
motor protein `stalling' before it begins to unwind the molecule through the
nanopore.

\input{plots/stall}

It consists of hundreds to thousands of data points which oscillate with little
variation around the read's median. The stall is a highly likely occurrence in
any read but its length and variance changes from read to read.  Only 6 reads in
the data set do not have a stall. The minimum stall length is 34 with a maximum
of \num{37128} and mean of 1140.33. But the standard deviation of stall lengths
is quite large at 1214.78. See Table \ref{tab:stall-n}. The standard deviation
of raw signal values in a stall is 5.72 compared to 35.07 for the whole data
set.

\input{plots/stall-n-tab}

We can take advantage of this section by compressing it separately if it is
large enough using the frame of reference algorithm followed by some encoding.
Since it oscillates with little variance around the read's median, the distance
from each point to the stall's minimum is smaller than in most other sections.
Instead of computing the zig-zag deltas we subtract the minimum point in the
stall from all other stall points then apply an entropy encoder such as
range coding.

The \textit{stall} encoding stores the stall's starting index (2 bytes), length
(2 bytes), compressed size (2 bytes) and compressed data (variable bytes)
followed by the non-stall's compressed size (4 bytes) and compressed data
(variable bytes). The stall is compressed using a \textit{stall-specific}
encoding, whilst the non-stall is compressed using a \textit{generic} algorithm.
See Figure \ref{fig:stall-enc}.
This method is more space-advantageous if
\[ C_{stall}(r) < C_{generic}(r) \]
where
\[ C_{stall}(r) = C_{specific}(r_s) + C_{generic}(r\setminus r_s) + 10 \]
and $r\in\Omega$ is a read from the space of possible reads and $r_s$ is the
read's stall section. That is, this method is advantageous if its total
compressed size, consisting of the compressed stall, the compressed non-stall
and 10 bytes of metadata, is less than the usual encoding.

\input{plots/stall-enc}

The encoding could dynamically make the above comparison to decide
whether the stall is worth encoding or not. Then it could store an extra bit (or
byte for convenience) to mark whether the stall or generic algorithm is being
used. Let's name this algorithm the \textit{dynamic stall} encoding or
\textit{dstall} for short. See Figure \ref{fig:dstall-enc}. However, this extra
byte is a waste of space if the large majority of reads benefit from separate
stall encoding.

\input{plots/dstall-enc}

Consider our stall-specific encoding to be the FOR encoding followed by the
compact variable byte exceptions encoding (vbbe21) and range coding (altogether
\textit{rc-vbbe21-for}). Due to its compression performance so far, let's
consider the generic algorithm to be rc-vbbe21-zd where \textit{zd} stands for
zig-zag delta. The stall encoding which uses the stall-specific encoding
rc-vbbe21-for and the generic encoding rc-vbbe21-zd we shall name
\textit{stall-fz}.

The compression ratio of the specific encoding rc-vbbe21-for outperforms
rc-vbbe21-zd more often than not on reads with stalls of length greater than or
equal to 1500. See Figure \ref{fig:stall-best}. This means we could simply
choose to encode the stall separately when its length is at least 1500. Let's
name this strategy \textit{dstall-fz-1500}. Since most stalls are smaller than
1500 in size let's store an extra byte at the beginning of the encoding to flag
whether the stall is being encoded or not. If not, the stall specific section is
not recorded at all. This is equivalent to the dstall encoding in Figure
\ref{fig:dstall-enc} with the exception of how the stall encoding decision is
made. The advantage is that the read only needs to be compressed once rather
than twice as in the dstall algorithm. This is because dstall must compare
compressing the stall separately to not and so must check both ways before
proceeding. On the other hand, the dstall-fz-1500 strategy approximates the
dstall-fz decision boundary and hence should be faster during compression with
no speed difference during decompression. The compression ratio will not be as
good as dstall-fz but there should be little difference.

%\input{plots/stall-ratio}
\input{plots/stall-best}

\subsection{The DNA Section}

\input{probspace/subseq}

\subsubsection{Separating the Jumps, Falls and Flats}

\input{plots/dna300-section}

The large majority of the data consists of DNA sections so any gains in
compression discovered by understanding this type of section should
result in the largest compression gains overall. Recall that the DNA sections of
nanopore signal data are characterised by many low-variance sections of 10--100
data points with steep transitions between them. See Figure
\ref{fig:dna300-section}. The low-variance sections will be named \textit{flats}
and the steep transitions up and down; \textit{jumps} and \textit{falls}
respectively.

The problem with compressing the DNA sections is that there are a lot of
apparent irregularities as is expected with information saturated sensor data.
Furthermore, the zig-zag delta transformation is quite fast and already has a
readily compressible distribution making it difficult to outperform.

However, we can take direct advantage of the signal's tendency to jump and fall
between flatter sections. Another useful observation is that the signal in a DNA
section doesn't tend to stray far from its median -- that is, if it moves
upwards it is more likely to move downwards next. This is clear if we refer back
to the distribution of deltas (Figure \ref{fig:delta-hist}) which is symmetric
except at the tails. Since flats oscillate around some level, they should have
small zig-zag deltas. On the other hand, jumps and flats should have larger
absolute deltas.

For this reason, consider separating the read into two distributions: the
zig-zag deltas of flats, and the absolute deltas of jumps and falls. This should
benefit compression since each distribution will have its own unique properties
which benefit from different compression strategies. However, storing the
metadata necessary for the reconstruction of the read from each distribution may
be too high of a cost to incur any space saving.

Let's define a jump or fall as
\begin{itemize}
	\item a sequence of length $m\ge 2$ which is
	\item strictly increasing or decreasing respectively ($\forall i$ $\delta_i>0$ or $\forall i$ $\delta_i < 0$) with
	\item at least one absolute delta greater than some $\epsilon$ ($\exists i$ $s.t.$ $|\delta_i|>\epsilon$).
\end{itemize}

The idea with the third restriction is to actually capture sudden movements
rather than slowly increasing or decreasing sections, without which all non-zero
deltas would be labelled part of a jump or fall. The choice of which $\epsilon$
depends on the data and how much separation between flats and jumps/falls one
desires. For example, consider Figure \ref{fig:epsilon}. Here, each jump and fall
is coloured by the maximum epsilon for which it is still considered a jump or
fall. In other words, it is coloured by its largest absolute delta
($\max_i\{|\delta_i|\}$). Furthermore, it is labelled by this maximum if it is
greater than 20. From visual observation it appears that setting $\epsilon=24$
may define the jumps and falls as is expected. Figure \ref{fig:epsilon-25}
highlights the jumps and falls for $\epsilon=24$.

\input{plots/epsilon}
\input{plots/epsilon-25}

The jumps encoding separates the two distributions by storing the number of
jumps and falls, the starting indices and lengths of the jumps and falls, the
absolute deltas of the jumps and falls, and finally the zig-zag deltas of the
flats. See Figure \ref{fig:jumps-enc} for more details. Since the deltas are
being encoded, the first point in the read must be recorded for invertibility.
Furthermore, because the falls have negative deltas, the absolute value of their
deltas is recorded. This means the jumps and falls deltas are all positive
whilst their distance from zero remains the same -- unlike what happens during
the zig-zag transformation where the data's distance from zero is roughly
doubled.

\input{plots/jumps-enc}

A caveat with doing this is that the starting positions of the jumps and flats
must be recorded since the interleaving order of the jumps and flats is not
maintained. An alternative approach would be to take the zig-zag deltas of the
jumps and flats and maintain their order. In which case, recording the starting
positions would not be necessary since the order has been maintained in the
zig-zag deltas data stream. The length of jumps which are followed by falls and
vice-versa could then be represented by a place-holder such as zero since the
end of the jump would be marked by a negative delta. This works because a
jump/fall or flat will never have a length of zero. However, a new data stream
would need to be used to mark when a jump/fall and a flat occurs. Consider a bit
stream where 1 is a jump/fall and 0 is a flat. The interesting observation is
that since flats will always be preceded and followed by a jump/fall, 0 will
always be surrounded by 1s in the bit stream. This gives the potential for
a reasonable compression strategy on the bit stream. Also the length of each
flat would need to be recorded as well, such as interleaved with the lengths of
the jumps and falls. See Figure \ref{fig:jumps-enc-alt1}.

\input{plots/jumps-enc-alt1}

For the regular jumps encoding, one compression strategy for the positions is to
take the deltas between the starting positions of the jumps and the deltas
between the starting positions of the falls. The initial jump and fall starting
position can be recorded beforehand. The deltas should be relatively small and
we can minus one as well since all jumps and falls are mutually exclusive.

% TODO choice of which position,length,jf,flats compression methods to use
% TODO analyse runtime
