\section{Exploiting the Signal}

As discussed in Section
\ref{sec:data:char},
there are several predictable characteristics among reads which can be exploited
to gain more compression.
We have already used statistical information about the zig-zag deltas to our
advantage in the vbbe21 encoding (Section \ref{sec:vbbe21}) but we can even
further exploit the signal's characteristics by intimately tying this knowledge
to a compression algorithm. This understanding should improve the compression
ratio since compression is fundamentally an artificial intelligence problem of
understanding and prediction.

\input{probspace/subseq}

\subsection{The Stall}

\input{plots/stall}

We will now explore stall-specific compression strategies.
Recall that the stall is the section of a read which occurs at
the beginning between the surge and pre-adapter surge. See Figure
\ref{fig:start-sections} for some context and Figure \ref{fig:stall} for a
close-up of the section. It is thought to occur due to the motor protein `stalling'
before it begins to unwind the molecule through the nanopore. It consists of
hundreds to thousands of data points which oscillate with little variation
around the read's median. The stall is a highly likely occurrence in any read,
for instance, only 6 reads in the data set do not have a stall.
However, its length varies from read to read, ranging from 34 to \num{37128}
with a mean of 1140.33. See Table \ref{tab:stall-n} for more information.

\input{plots/stall-n-tab}

Since this section oscillates with little variance around the read's median,
the maximum and minimum are much closer than in the DNA section.
Notably, the standard deviation of raw signal values in a stall is 5.72 compared
to 35.07 for the whole data set.
Instead of computing the zig-zag deltas we could transform the stall by subtract
its minimum point from all other stall points (FOR encoding) then
apply a suitable compression algorithm such as range coding. The idea is that
this could create a distribution with a lower entropy than the stall's zig-zag
deltas and hence more potential for compression.

Now we will define this strategy more formally. The \textit{stall} encoding
stores the stall's starting index (2 bytes), length (2 bytes), compressed size
(2 bytes) and compressed data (variable bytes) followed by the non-stall's
compressed size (4 bytes) and compressed data (variable bytes). The stall is
compressed using a \textit{stall-specific} encoding, whilst the non-stall is
compressed using a \textit{generic} algorithm.  See Figure \ref{fig:stall-enc}.
This method is more space-advantageous if
\[ C_{stall}(r) < C_{generic}(r) \]
where
\[ C_{stall}(r) = C_{specific}(r_s) + C_{generic}(r\setminus r_s) + 10. \]
In the above equations, $r\in\Omega$ is a read from the space of possible reads and $r_s$ is the
read's stall section. That is, this method is advantageous if its total
compressed size, consisting of the compressed stall, the compressed non-stall
and 10 bytes of metadata, is less than the usual encoding.

\input{plots/stall-enc}

The encoding could dynamically make the above comparison to decide
whether the stall is worth encoding or not. Then it could store an extra bit (or
byte for convenience) to flag whether the stall or generic algorithm is being
used. Let's name this algorithm the \textit{dynamic stall} encoding or
\textit{dstall} for short. See Figure \ref{fig:dstall-enc}. However, this extra
byte is a waste of space if the large majority of reads benefit from separate
stall encoding.

\input{plots/dstall-enc}

Consider our stall-specific encoding to be the FOR encoding followed by the
regular vbbe21 encoding (vbbe21) and range coding (altogether
\textit{rc-vbbe21-for}). Furthermore, let the generic algorithm be the
vbbe21-zd encoding followed by range coding (altogether
\textit{rc-vbbe21-zd}).
We shall name the stall encoding which uses the stall-specific encoding
rc-vbbe21-for and the generic encoding rc-vbbe21-zd: \textit{stall-fz}.
Similarly, we shall name \textit{dstall-fz} the dstall encoding which uses the
same stall-specific and generic encodings as stall-fz.

The compression ratio of stall-fz outperforms the generic method rc-vbbe21-zd
more often than not on reads with stalls of length greater than or equal to
1500. See Figure
\ref{fig:stall-best}. This means we could simply choose to encode the stall
separately when its length is at least 1500. Let's name this strategy
\textit{dstall-fz-1500}. Since most stalls are smaller than
1500 in size let's store an extra byte at the beginning of the encoding to flag
whether the stall is being encoded or not. If not, the stall specific section is
not recorded at all. This is equivalent to the dstall encoding in Figure
\ref{fig:dstall-enc} with the exception of how the stall encoding decision is
made. The advantage is that the read only needs to be compressed once rather
than twice as in the dstall algorithm. This is because dstall must compare
compressing the stall separately to not and so must check both ways before
proceeding. On the other hand, the dstall-fz-1500 strategy approximates the
dstall-fz decision boundary and hence should be faster during compression with
no speed difference during decompression. The compression ratio of
dstall-fz-1500 will not be better than dstall-fz but there should be little
difference if the decision boundary approximation is good.

%\input{plots/stall-ratio}
\input{plots/stall-best}

\subsection{The DNA Section}

\input{plots/dna300-section}

The large majority of the data consists of DNA sections so any gains in
compression discovered by understanding this type of section should
result in the largest compression gains overall. Recall that the DNA sections of
nanopore signal data are characterised by many low-variance subsequences of 10--100
data points with steep transitions between them. See Figure
\ref{fig:dna300-section} for an example.

The problem with compressing the DNA sections is that there are a lot of
apparent irregularities as is expected with information saturated sensor data.
Furthermore, the zig-zag delta transformation is quite fast and produces a lower
entropy distribution which is readily compressible making it difficult to outperform.

\subsubsection{Separating the Jumps, Falls and Flats}

However, since we expect many low-variance sections with steep transitions
between them we can separate these two types of sections and compress each
separately. We will name the low-variance sections \textit{flats} and the
steep transitions up and down; \textit{jumps} and \textit{falls} respectively.
Since flats oscillate around some level, they should have small zig-zag deltas.
On the other hand, jumps and flats should have larger absolute deltas.

%Another useful observation is that the signal in a DNA
%section doesn't tend to stray far from its median -- that is, if it moves
%upwards it is more likely to move downwards next. This is clear if we refer back
%to the distribution of deltas (Figure \ref{fig:delta-hist}) which is symmetric
%except at the tails.

%However, we can take direct advantage of the signal's tendency to jump and fall
%between flatter sections.

For this reason, consider separating the read into two distributions: the
zig-zag deltas of flats, and the absolute deltas of jumps and falls. This should
benefit compression since each distribution will have its own unique properties
which benefit from different compression strategies. However, storing the
metadata necessary for the reconstruction of the read from each distribution may
be too high of a cost to incur any space saving.

Let's define a jump or fall as
\begin{itemize}
	\item a sequence of length $m\ge 2$ which is
	\item strictly increasing or decreasing respectively ($\forall i$ $\delta_i>0$ or $\forall i$ $\delta_i < 0$) with
	\item at least one absolute delta greater than some $\epsilon$ ($\exists i$ $s.t.$ $|\delta_i|>\epsilon$).
\end{itemize}

The idea with the third restriction is to actually capture sudden movements
rather than slowly increasing or decreasing sections, without which all non-zero
deltas would be labelled part of a jump or fall. The choice of which $\epsilon$
depends on the data and how much separation between flats and jumps/falls one
desires. For example, consider Figure \ref{fig:epsilon}. Here, each jump and fall
is coloured by the maximum epsilon for which it is still considered a jump or
fall. In other words, it is coloured by its largest absolute delta
($\max_i\{|\delta_i|\}$). Furthermore, it is labelled by this maximum if it is
greater than 20. From visual observation it appears that setting $\epsilon=24$
may define the jumps and falls as is expected. Figure \ref{fig:epsilon-25}
highlights the jumps and falls for $\epsilon=24$.

\input{plots/epsilon}
\input{plots/epsilon-25}

The jumps encoding separates the two distributions by storing the number of
jumps and falls, the starting indices and lengths of the jumps and falls, the
absolute deltas of the jumps and falls, and finally the zig-zag deltas of the
flats. See Figure \ref{fig:jumps-enc} for more details. Since the deltas are
being encoded, the first point in the read must be recorded for invertibility.
Furthermore, because the falls have negative deltas, the absolute value of their
deltas is recorded. This means the jumps and falls deltas are all positive
whilst their distance from zero remains the same -- unlike what happens during
the zig-zag transformation where the data's distance from zero is roughly
doubled.

\input{plots/jumps-enc}

A caveat with doing this is that the starting positions of the jumps and flats
must be recorded since the interleaving order of the jumps and flats is not
maintained. An alternative approach would be to take the zig-zag deltas of the
jumps and flats and maintain their order. In which case, recording the starting
positions would not be necessary since the order has been maintained in the
zig-zag deltas data stream. The length of jumps which are followed by falls and
vice-versa could then be represented by a place-holder such as zero since the
end of the jump would be marked by a negative delta. This works because a
jump/fall or flat will never have a length of zero. However, a new data stream
would need to be used to mark when a jump/fall and a flat occurs. Consider a bit
stream where 1 is a jump/fall and 0 is a flat. The interesting observation is
that since flats will always be preceded and followed by a jump/fall, 0 will
always be surrounded by 1s in the bit stream. This gives the potential for
a reasonable compression strategy on the bit stream. In addition, the length of each
flat would need to be recorded, such as by combining them with the lengths of
the jumps and falls. See Figure \ref{fig:jumps-enc-alt1}.

\input{plots/jumps-enc-alt1}

For the regular jumps encoding, one compression strategy for the positions is to
take the deltas between the starting positions of the jumps and the deltas
between the starting positions of the falls. The initial jump and fall starting
position can be recorded beforehand. The deltas should be relatively small and
we can minus one as well since all jumps and falls are mutually exclusive.

% TODO choice of which position,length,jf,flats compression methods to use
% TODO analyse runtime
