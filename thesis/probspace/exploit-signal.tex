\section{Exploiting the Signal}

As discussed in Section
\ref{sec:data:char},
there are several predictable characteristics among reads which can be exploited
to gain more compression.

\subsection{The Stall}

To begin with, recall that the stall is the section of a read which occurs at
the beginning between the surge and pre-adapter surge. See Figures
\ref{fig:start-sections} and \ref{fig:stall}. It is thought to occur due to the
motor protein `stalling' before it begins to unwind the molecule through the
nanopore.

\input{plots/stall}

It consists of hundreds to thousands of data points which oscillate with little
variation around the read's median. The stall is a highly likely occurrence in
any read but its length and variance changes from read to read.  Only 6 reads in
the data set do not have a stall. The minimum stall length is 34 with a maximum
of \num{37128} and mean of 1140.33. But the standard deviation is quite large at
1214.78. See Table \ref{tab:stall-n}. The standard deviation of raw signal
values in a stall is 5.72 compared to 35.07 for the whole data set.

\input{plots/stall-n-tab}

We can take advantage of this section by compressing it separately if it is
large enough using the frame of reference algorithm followed by some encoding.
Since it oscillates with little variance around the read's median, the distance
from each point to the stall's minimum is smaller than in most other sections.
Instead of computing the zig-zag deltas we subtract the minimum point in the
stall from all other stall points then apply an entropy encoder such as
rc-vbe21.

The \textit{stall} encoding stores the stall's starting index (2 bytes), length
(2 bytes), compressed size (2 bytes) and compressed data (variable bytes)
followed by the non-stall's compressed size (4 bytes) and compressed data
(variable bytes). The stall is compressed using a \textit{stall-specific}
encoding, whilst the non-stall is compressed using a \textit{generic} algorithm.
This method is more space-advantageous if
\[ C_{stall}(r) = C_{specific}(r_s) + C_{generic}(r\setminus r_s) + 10 < C_{generic}(r) \]
where $r\in\Omega$ is a read from the space of possible reads and $r_s$ is the
read's stall section. That is, this method is advantageous if its total
compressed size, consisting of the compressed stall, the compressed non-stall
and 10 bytes of metadata, is less than the usual encoding.

% TODO put diagram of encoding

The encoding could actually dynamically make the above comparison to decide
whether the stall is worth encoding or not. Then it could store an extra bit (or
byte for convenience) to mark whether the stall or generic algorithm is being
used. Let's name this algorithm the \textit{dynamic stall} encoding or
\textit{dstall} for short. However, this extra bit or byte is a waste of space
if the large majority of reads benefit from one encoding more than the other.

Consider our stall-specific encoding to be the FOR encoding followed by the
compact variable byte exceptions encoding (vbbe21) and range coding (altogether
\textit{rc-vbbe21-for}). Due to its compression performance so far, let's
consider the generic algorithm to be rc-vbbe21-zd where \textit{zd} stands for
zig-zag delta. The stall encoding which uses the stall-specific encoding
rc-vbbe21-for and the generic encoding rc-vbbe21-zd we shall name
\textit{stall-fz}. The compression ratio of this encoding outperforms
rc-vbbe21-zd more often than not on reads with stalls of length greater than or
equal to 1500. See Figure \ref{fig:stall-ratio}.

\input{plots/stall-ratio}
\input{plots/stall-best}

\subsection{Separating the Jumps and Flats}

The large majority of the data consists of DNA sections so any gains in
compression discovered by understanding this type of section should
result in the largest compression gains overall.

The problem is that there are a lot of apparent irregularities in the DNA
sections as is expected with information saturated sensor data. Furthermore, the
zig-zag delta transformation is quite fast and already has a readily
compressible distribution making it difficult to outperform. However, one
observation we could take advantage of is the fact that the signal tends to
suddenly move up or down between `flat' sections which oscillate around some
level. See Figure \ref{fig:dna300-section}. Another observation is that the
signal tends to move around the same median -- that is, if it moves up it is
more likely to move down soon. This is obvious if we refer back to the
distribution of deltas (Figure \ref{fig:delta-hist}) where it is clearly
symmetric except at the tails.

\input{plots/dna300-section}

Let's call these sudden movements up and down, `jumps' and `falls'
respectively. Whilst `flats' will be our name for sections which oscillate
around some level. Since flats oscillate around some level, they should have
small zig-zag deltas. On the other hand, jumps and flats should have larger
absolute deltas.

Consider separating the read into two general distributions: the zig-zag deltas
of flats, and the absolute deltas of jumps and falls. This should benefit
compression since each distribution will have its own unique properties which
benefit from different compression strategies. However, storing the metadata
necessary for reconstruction of the read from the distributions may be too much
of a cost for any benefits received.

Let's define a jump or fall as
\begin{itemize}
	\item a sequence of length $m\ge 2$ which is
	\item strictly increasing or decreasing respectively ($\forall i$ $\delta_i>0$ or $\forall i$ $\delta_i < 0$) with
	\item at least one absolute delta greater than some $\epsilon$ ($\exists i$ $s.t.$ $|\delta_i|>\epsilon$).
\end{itemize}

The idea with the third restriction is to actually capture sudden movements
rather than slowly increasing or decreasing sections, without which all non-zero
deltas would be labelled part of a jump or fall. The choice of which $\epsilon$
depends on the data and how much separation between flats and jumps or falls you
desire. For example, consider Figure \ref{fig:epsilon}. Here, each jump and fall
is coloured by its maximum epsilon or maximum absolute delta
($\max_i\{|\delta_i|\}$) and labelled if this maximum is greater than 20. From
visual observation it appears that setting $\epsilon=24$ may define the jumps
and falls as is expected. Figure \ref{fig:epsilon-25} highlights the jumps and
falls for $\epsilon=24$.

\input{plots/epsilon}
\input{plots/epsilon-25}
