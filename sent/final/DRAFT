time: 20 minutes
questions: 5-10 minutes

- motivation/objective

When a human DNA sample is sequenced using nanopore technology, around half a
trillion data points are recorded.
Half a trillion also happens to be the surface area of the Earth in metres
squared - so we're talking about a lot of data here.
This data is regularly recorded, analysed and then archived for up to
10 years.
As you can imagine, this process results in some very large archives.
To appreciate the scale of data being recorded, consider the Garvan Institute of
Medical Research. My colleagues at Garvan are producing up to half a petabyte
each year. Using Google Cloud storage to archive this data would cost up to 100
grand a year - that's not cheap.

One solution to reducing these storage costs is data compression.
Data compression represents data in a clever way which uses less bits than the
original.
The state-of-the-art compression method for nanopore data reduces it to
34.1% of its original size.
However, this method does not consider the data's unique properties. Therefore,
a more targetted compression method for nanopore data which understands its
characteristics should be able to compress it even smaller than the
state-of-the-art. This would then alleviate some of the financial costs that
come with archiving nanopore data.

Hence, my objective was to design a compression method which (1) outperforms the
state-of-the-art in terms of compressed size, and (2) is suitable for most
nanopore applications. Now, I will present to you the background literature
necessary for understanding my work.

- background lit

Nanopore sequencing, which emerged in the 1980s, is one approach used in
bioinformatics to determine the order of DNA nucleobases in a molecule. That is,
the sequence of DNA bases A,C,T and G. It achieves this by recording the ionic
current as a DNA molecule passes through a nanoscale protein pore (or nanopore).
Disturbances in the current signal are used by computational algorithms to
determine the molecule's DNA sequence.

The MinION is the most portable nanopore sequencer weighing only half a
kilogram. It consists of one flow cell with thousands of nanopores in groups of
four. Each group is assigned an electrode from the sensor chip which is
controlled and measured by the ASIC. A DNA sample is inserted into the flow cell
and its many DNA strands pass through the available nanopores in parallel. Each
time a strand passes through a nanopore, a signal known as a read is a recorded
and digitised as a sequence of 16-bit signed integers. Nanopore data thus
consists of many of these read sequences.

Now, let's move on to compression. Data compression is the process of encoding
information using fewer bits. There are two main classes; lossless and lossy.
Lossless compression does not lose information in the process of encoding, such
that the original data can be fully reconstructed. This reconstruction process
is known as decompression. Lossy compression, on the other hand, partially
discards information such that only an approximate replica of the original data
can be obtained through decompression. Lossy compression can achieve better
space saving at the cost of inaccuracy.

Data compression relies on the framework of information theory established by
Shannon in 1948. Shannon introduced the concept of information entropy which is
the average level of information or uncertainty inherent in a random variable.
He showed that the entropy is mathematical limit on how well a data stream can
be losslessly compressed. That is, a lossless compression method can approach
the entropy of a data source by removing statistical redundancies, or wasted
space.

Entropy coding is a class of data compression which attempts to reach the
entropy of the data source. This is typically achieved through encoding
fixed-width symbols with variable-length binary codes. Huffman coding is one
such compression method which recursively constructs a binary tree from the
bottom up. The two symbols with the lowest frequency are used to construct a new
node. This node is the parent of the two symbols and has their combined
frequency. This process continues until there is only one node left which is the
root of the tree. The code of each symbol is then found by traversing the tree
from root to leaf and concatenating a 0 if the left edge is taken, otherwise a
1. Among all methods which replace symbols with codes, where the probability
distribution of the alphabet is known beforehand - Huffman coding achieves the
smallest compressed size.

However, arithmetic or range coding can compress smaller and closer to the
entropy of the data by replacing the data with number in a range.

-- svb
-- for
-- wavelets
-- nanopore compression
-- state-of-the-art

- method

-- data
-- one byte two byte exceptions
-- the stall
-- subsequence searching
-- dna section

- main results
- discussion/evaluation/contribution
- conclusion/future work

Large data sets produced from nanopore sequencing are regularly recorded
and often require long-term archiving due to strict research and clinical data
regulations.

